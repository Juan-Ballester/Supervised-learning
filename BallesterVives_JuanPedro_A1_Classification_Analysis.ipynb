{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b42af6",
   "metadata": {},
   "source": [
    "First the libraries and packages needed will be imported, also the file and information about the dataset will be looked at to see if first of all there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9f5162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1946 entries, 0 to 1945\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   S.No                        1946 non-null   int64  \n",
      " 1   name                        1946 non-null   object \n",
      " 2   title                       938 non-null    object \n",
      " 3   culture                     677 non-null    object \n",
      " 4   dateOfBirth                 433 non-null    float64\n",
      " 5   mother                      21 non-null     object \n",
      " 6   father                      26 non-null     object \n",
      " 7   heir                        23 non-null     object \n",
      " 8   house                       1519 non-null   object \n",
      " 9   spouse                      276 non-null    object \n",
      " 10  book1_A_Game_Of_Thrones     1946 non-null   int64  \n",
      " 11  book2_A_Clash_Of_Kings      1946 non-null   int64  \n",
      " 12  book3_A_Storm_Of_Swords     1946 non-null   int64  \n",
      " 13  book4_A_Feast_For_Crows     1946 non-null   int64  \n",
      " 14  book5_A_Dance_with_Dragons  1946 non-null   int64  \n",
      " 15  isAliveMother               21 non-null     float64\n",
      " 16  isAliveFather               26 non-null     float64\n",
      " 17  isAliveHeir                 23 non-null     float64\n",
      " 18  isAliveSpouse               276 non-null    float64\n",
      " 19  isMarried                   1946 non-null   int64  \n",
      " 20  isNoble                     1946 non-null   int64  \n",
      " 21  age                         433 non-null    float64\n",
      " 22  numDeadRelations            1946 non-null   int64  \n",
      " 23  popularity                  1946 non-null   float64\n",
      " 24  isAlive                     1946 non-null   int64  \n",
      "dtypes: float64(7), int64(10), object(8)\n",
      "memory usage: 380.2+ KB\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Importing packages.\n",
    "########################################\n",
    "import matplotlib.pyplot as plt                      # Data visualization.\n",
    "import seaborn as sns                                # Data visualization.\n",
    "import pandas as pd                                  # Data science essentials.\n",
    "from sklearn.model_selection import train_test_split # Train-test split.\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regressio.\n",
    "import statsmodels.formula.api as smf                # Logistic regression.\n",
    "from sklearn.metrics import roc_auc_score            # Auc score.\n",
    "from sklearn.metrics import confusion_matrix         # Confusion matrix.\n",
    "from scipy.stats import pearsonr                     # Correlation.\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest.\n",
    "from sklearn.datasets import make_classification     # Random Forest.\n",
    "\n",
    "# CART model packages.\n",
    "from sklearn.tree import DecisionTreeClassifier      # Classification trees.\n",
    "from sklearn.tree import plot_tree                   # Tree plots.\n",
    "\n",
    "\n",
    "# Importing for hyperparamter tuning.\n",
    "from sklearn.model_selection import RandomizedSearchCV     # Hyperparameter tuning.\n",
    "from sklearn.metrics import make_scorer              # Customizable scorer.\n",
    "\n",
    "\n",
    "########################################\n",
    "# Loading data and setting display options.\n",
    "########################################\n",
    "# Loading data.\n",
    "file = './__dataset/GOT_character_predictions.xlsx'\n",
    "got = pd.read_excel(io = file)\n",
    "# Setting display options.\n",
    "pd.set_option('display.max_rows', got.shape[0]+1, \"display.max_columns\", \n",
    "              got.shape[0]+1)\n",
    "# Getting data info.\n",
    "got.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b0992",
   "metadata": {},
   "source": [
    "Now I will use the professors function to flag missing values and create new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12c73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined functions\n",
    "\n",
    "#########################\n",
    "# mv_flagger\n",
    "#########################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm-COLUMN_NAME'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# text_split_feature\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212dbcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.No                          False\n",
       "name                          False\n",
       "title                          True\n",
       "culture                        True\n",
       "dateOfBirth                    True\n",
       "mother                         True\n",
       "father                         True\n",
       "heir                           True\n",
       "house                          True\n",
       "spouse                         True\n",
       "book1_A_Game_Of_Thrones       False\n",
       "book2_A_Clash_Of_Kings        False\n",
       "book3_A_Storm_Of_Swords       False\n",
       "book4_A_Feast_For_Crows       False\n",
       "book5_A_Dance_with_Dragons    False\n",
       "isAliveMother                  True\n",
       "isAliveFather                  True\n",
       "isAliveHeir                    True\n",
       "isAliveSpouse                  True\n",
       "isMarried                     False\n",
       "isNoble                       False\n",
       "age                            True\n",
       "numDeadRelations              False\n",
       "popularity                    False\n",
       "isAlive                       False\n",
       "m_title                       False\n",
       "m_culture                     False\n",
       "m_dateOfBirth                 False\n",
       "m_mother                      False\n",
       "m_father                      False\n",
       "m_heir                        False\n",
       "m_house                       False\n",
       "m_spouse                      False\n",
       "m_isAliveMother               False\n",
       "m_isAliveFather               False\n",
       "m_isAliveHeir                 False\n",
       "m_isAliveSpouse               False\n",
       "m_age                         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the mv_flagger function\n",
    "got = mv_flagger(df = got)\n",
    "\n",
    "\n",
    "# checking results\n",
    "got.columns\n",
    "\n",
    "\n",
    "#checking for missing values\n",
    "got.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02021c71",
   "metadata": {},
   "source": [
    "Now the objective will be to engineer the sex of the observations, for this, using the titanic idea, a loop will be created to find 'male' roles in the titles and assign values to them. The logic behind this will be that since there are more male titles, and more specific ones, the males will take a 1 and the females or the unknown a 0. This way we will know at least who is male guaranteed and the error will lie in the female side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282591c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Making sure that it is all string.\n",
    "got['title'] = got['title'].astype(str)\n",
    "# Finding titles if male or female and assigning them to new feature.\n",
    "got['male'] = 0\n",
    "# Creating loop to run through the dataframe.\n",
    "for index, val in got.iterrows():\n",
    "     # Checking for male titles.\n",
    "    if ('lord' in got.loc[ index , 'title'].lower() \n",
    "        or 'ser'in got.loc[ index , 'title'].lower() \n",
    "        or 'hand'in got.loc[ index , 'title'].lower() \n",
    "        or 'archmaester' in got.loc[ index , 'title'].lower()\n",
    "        or 'maester' in got.loc[ index , 'title'].lower()\n",
    "        or 'khal' in got.loc[ index , 'title'].lower()\n",
    "        or'brother' in got.loc[ index , 'title'].lower()\n",
    "        or 'prince' in got.loc[ index , 'title'].lower()\n",
    "        or 'septon' in got.loc[ index , 'title'].lower()\n",
    "        or 'king' in got.loc[ index , 'title'].lower()\n",
    "        or 'senschal' in got.loc[ index , 'title'].lower()\n",
    "        or 'bloodrider'in got.loc[ index , 'title'].lower()\n",
    "        or 'steward' in got.loc[ index , 'title'].lower()\n",
    "        or 'cupbearer'in got.loc[ index , 'title'].lower()\n",
    "        or 'master' in got.loc[ index , 'title'].lower()\n",
    "        or 'captain' in got.loc[ index , 'title'].lower()\n",
    "        or'general'in got.loc[ index , 'title'].lower()\n",
    "        or 'commander'in got.loc[ index , 'title'].lower()\n",
    "        or 'sword'in got.loc[ index , 'title'].lower()\n",
    "        or 'ranger'in got.loc[ index , 'title'].lower()\n",
    "        or 'knight'in got.loc[ index , 'title'].lower()\n",
    "        or 'sealord' in got.loc[ index , 'title'].lower()):\n",
    "         got.loc[index, 'male'] = 1\n",
    "\n",
    "        # Checking for female titles. \n",
    "    elif ('queen' in got.loc[ index , 'title'].lower()\n",
    "        or 'red'in got.loc[ index , 'title'].lower()\n",
    "        or 'princess'in got.loc[ index , 'title'].lower() \n",
    "        or 'lady'in got.loc[ index , 'title'].lower()\n",
    "        or 'septa' in got.loc[ index , 'title'].lower()\n",
    "        or 'bride' in got.loc[ index , 'title'].lower()\n",
    "        or'goodwife'in got.loc[ index , 'title'].lower() \n",
    "        or 'witch' in got.loc[ index , 'title'].lower()\n",
    "        or 'pinkmaiden'in got.loc[ index , 'title'].lower() \n",
    "        or 'widow' in got.loc[ index , 'title'].lower()):\n",
    "        got.loc[index, 'male'] = 0\n",
    "    else:\n",
    "        got.loc[index, 'male'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03db58",
   "metadata": {},
   "source": [
    "Now the idea is to analyze the data. Just looking at the variables there were two that directly pointed out that they were related, dateOfBirth and age should be completely correlated but in a negative way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d954245d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAGDCAYAAADQ9S0AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhi0lEQVR4nO3debhlV10n/O8vqcwDSUiBIQkUyCBIy1QgkwMgo9gMItIvSFCavLSNOAA2GFFQWwXRphEb3oAILcgU4TUiU2RUCcFKTCAhQAgECAlJhRAShg4Ef/3H2QU3N/fedatS956b4vN5nvPcc9feZ691ztq76nvXWXvv6u4AAADL22veDQAAgI1OaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGVg3VfVbVfXK3b3uKrbVVXXr6/H63daWaXtfq6pbTc9fXVV/sBu3/fKqeu7u2t5O1PtfquqS6b3deCdf+5NVdeFatW2VbbhdVf1bVV1VVU9fxfqPr6p372Qdc3+fwK4TmoFdUlVPqqqPVdU3qupLVfWyqjpspdd09x92939ezfZ3Zt3ro6reX1X/ZwpLV1bV6VX17Krab2fbMm1ruF53H9zdn9kNbX9SVf3zom0/tbt///pueyfbsU+SP0vyoOm9fXkN67rOe17Faw6b9s8vTfvrx6rqFxet9ptJ3t/dh3T3S6Y/Zr41/RFw1bRf/MSOlbv7dd39oEG91+uPNWBjEZqBnVZVz0jygiTPSnKjJPdMcoskp1TVvsu8ZtP6tXCnPa27D0lyVJJnJHlckrdXVe3OSjb4Z3B93DTJ/knOmXdDFpv2x3/MbP+8V2b767OS/HFV/caCVW+R67b/hd198PSalyV5S1XtvYo699R+hu9rQjOwU6rq0CTPT/Ir3f3O7v52d1+Q5LGZBY8nTOs9r6pOqqrXVtWVSZ40lb12wbaeWFWfq6ovV9Vzq+qCqvqpBa9/7fR8yzRqd1xVfb6qLquqExZs5x5VdWpVXVFVF1fVS5cL7yvp7q939/uT/MfMAtZPL9GW/af39OWpvn+tqptW1X9P8mNJXjqNTr50Wr+r6r9W1XlJzltQtnAE8siqOmUa0fxAVd1i0fv+bgjbMZpdVbdP8vIk95rqu2Jafq3pHlX1lKr6dFVdXlUnV9XNFizrqnpqVZ1XVV+pqr9Y7g+Fqtqvql5cVRdNjxdPZbdN8slptSuq6r2jz7mqDpja+ZWq+niSuy9a/uyqOn/6PD5eVY+aypd7z/tV1YumfeOSmk1ROWDa3C8kuXmSn+vuz0776zuTPD3J71XVoVOb77eg7267sD3d/e9J/ibJEZn9gXCdEe/F/VxVH5wWnTVt8+cXrPuMqrp02lcXj3gDG5TQDOyse2c2qviWhYXd/bUk70jywAXFj0hyUpLDkrxu4fpVdYck/yvJ4zMb4b1RkqMHdd83ye2SPCDJ70whKkm+k+TXkxyZWdh9QJJf3rm3da338vkk2zILwYsdN7X12CQ3TvLUJN/s7hOS/FNmo9YHd/fTFrzmkUl+NMkdlqny8Ul+f2r/mVn0WS3TxnOnuk+d6jts8TpVdf8kf5TZHzRHJflckjcsWu3hmYXWO03rPXiZKk/I7BuFO0/r3iPJb3f3p5L88LTOYd19/6q6+fQHxc2X2dbvJvnB6fHgzD7Thc7P7LO/UWZ/oL22qo5a4T2/IMltp7bdOrP96HemZQ9M8o7u/vqiOv42s/34Xt19/1y77z61cMVpdPmJST6b5JJl3lOyoJ+7+8ensjtN23zj9PsP5Hv7+pOT/EVVHb7CNoENQmgGdtaRSS7r7muWWHbxtHyHU7v7/+/uf+/uby5a9zFJ/r67/7m7v5VZyOlB3c/v7m9291lJzsosvKW7T+/uD3f3NdOo9/+X5CdW2M5qXJTZyOJi384sLN+6u78z1X3lYFt/1N2XL/EZ7PAP3f3B7r46s3B6r6o6dteb/l2PT/Kq7j5j2vZzpm1vWbDOH3f3FdMfCu/LLHgut63f6+5Lu3t7ZmH2F5Zasbs/392HTdtcymOT/PfpM/lCkpcsev2bu/uiab95Y2Yj9PdYakPTyPhTkvz6tL2rkvxhZlNsktn+ePESbbwmyWW59v662DOn0eyvJ3lxkud293dWWH/Uz8ls//m9acT77Um+ltkfgsAGJzQDO+uyzKYTLDVv86hp+Q5fWGE7N1u4vLu/kWR0AtmXFjz/RpKDk6SqbltVb6vZiV5XZhaaVgpDq3F0ksuXKP/rJO9K8oZpmsILa3Yi3EpW+hyutXwasb88s8/n+rpZZqPLC7f95Vx7RH/Jz3S0ren5rrbxWn2/aLs7pu2cOY1WX5Hkjlm+PzcnOTDJ6QvWf+dUnsz2x6MWv2jaf4/MtffXxV40jWYfkGRrkj+pqoeusP6on5Pky4v+4FzpMwc2EKEZ2FmnJrk6yaMXFlbVQUkemuQ9C4pXGjm+OMkxC15/QGYjuLviZUk+keQ23X1okt9Ksssn8U2jvHfL7Cv7a5lGCJ/f3XfIbKrKwzP76j5Z/v2ORtC/O6pcVQdnNsJ9UWYjnMksFO7wAzux3Ysym2e+Y9sHZfYZf3HwuuG2MpsnfNEubCeZ9f3CkfTvTuOY5nO/IsnTktx4Cq1n53v9ufg9X5bkm0l+eBrdPqy7bzSdwJfMTgJ86PTeF/rZzPbjD48a2zNnJ/mXTPPcl1t1tC3ghktoBnZKd381s6/m/7yqHlJV+0xf9785yYWZjcSuxklJfqaq7j2dtPf87HrQPSTJlUm+VlU/lOS/7MpGqurAml1W7O+SfCTJ25dY535V9R+mea5XZvZ1+46v7C9JcqtdqPphVXXf6XP4/SSndfcXpmkQX0zyhKrau6p+KbN5wDtckuSYWv6kx79J8otVdeeaXULvD6dtX7ALbXx9kt+uqs1VdWRm02leO3jNct6U5DlVdXhVHZPkVxYsOyiz8Lk9SaYT5e64YPm13vN0kt4rkvyPqrrJ9Jqjq2rH3Oy/zmy/fHPNTqzcZ1r2kiTPm/bnoWm/um927gohu7o/ABuQ0AzstO5+YWajuS/KLDieltlX0w+Y5s6uZhvnZBaW3pDZyONVSS7NbPRvZz0zyf8zbeMVSd648urX8dKquiqzkPPizE4Se8gUyBb7gcwC/5VJzk3ygXwvPP7PJI+ZrgrxkiVeu5y/yezkuMszG+F+/IJlT8nsEmlfzuyEuw8tWPbezELcl6rqOtMMuvs9SZ47vZ+LMwvcj1u83ir9QWYnR340yceSnDGVXcd0IuDXVjgR8PmZTcn4bJJ3Z8EfWt398SR/mtk3Gpck+Q+ZjfDusNR7/m9JPp3kw9P0nH/MNE942h9/KrP987TM+u3PkpzQ3X8yeM+/Ob2Pr0/t/KvM5suv1vOSvGaaNvLYnXgdsAFVt2+TgPmbpiVckdkUi8/OuTkAcC1GmoG5qaqfmaZEHJTZqPXHklww31YBwHUJzcA8PSKzk8kuSnKbJI9rX38BsAGZngEAAANGmgEAYEBoBgCAgaXu6LXhHHnkkb1ly5Z5NwMAgD3c6aeffll3b15cfoMIzVu2bMm2bdvm3QwAAPZwVfW5pcpNzwAAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYWLPQXFWvqqpLq+rsBWV/UlWfqKqPVtVbq+qwtaofAAB2l7UcaX51kocsKjslyR27+0eSfCrJc9awfgAA2C3WLDR39weTXL6o7N3dfc3064eTHLNW9QMAwO4yzznNv5TkHXOsHwAAVmUuobmqTkhyTZLXrbDO8VW1raq2bd++ff0aBwAAi6x7aK6q45I8PMnju7uXW6+7T+zurd29dfPmzevXQAAAWGTTelZWVQ9J8t+S/ER3f2M96wYAgF21lpece32SU5PcrqourKonJ3lpkkOSnFJVZ1bVy9eqfgAA2F3WbKS5u//TEsV/uVb1AQDAWnFHQAAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGFiz0FxVr6qqS6vq7AVlR1TVKVV13vTz8LWqHwAAdpe1HGl+dZKHLCp7dpL3dPdtkrxn+h0AADa0NQvN3f3BJJcvKn5EktdMz1+T5JFrVT8AAOwu6z2n+abdfXGSTD9vss71AwDATtuwJwJW1fFVta2qtm3fvn3ezQEA4PvYeofmS6rqqCSZfl663IrdfWJ3b+3urZs3b163BgIAwGLrHZpPTnLc9Py4JH+3zvUDAMBOW8tLzr0+yalJbldVF1bVk5P8cZIHVtV5SR44/Q4AABvaprXacHf/p2UWPWCt6gQAgLWwYU8EBACAjUJoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAgbmE5qr69ao6p6rOrqrXV9X+82gHAACsxrqH5qo6OsnTk2zt7jsm2TvJ49a7HQAAsFrzmp6xKckBVbUpyYFJLppTOwAAYGjdQ3N3fzHJi5J8PsnFSb7a3e9evF5VHV9V26pq2/bt29e7mQAA8F3zmJ5xeJJHJLllkpslOaiqnrB4ve4+sbu3dvfWzZs3r3czAQDgu+YxPeOnkny2u7d397eTvCXJvefQDgAAWJV5hObPJ7lnVR1YVZXkAUnOnUM7AABgVeYxp/m0JCclOSPJx6Y2nLje7QAAgNXaNI9Ku/t3k/zuPOoGAICd5Y6AAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMCA0AwAAAOrCs1VdZ/VlAEAwJ5otSPNf77KMgAA2ONsWmlhVd0ryb2TbK6q31iw6NAke69lwwAAYKNYMTQn2TfJwdN6hywovzLJY9aqUQAAsJGsGJq7+wNJPlBVr+7uz61TmwAAYEMZjTTvsF9VnZhky8LXdPf916JRAACwkaw2NL85ycuTvDLJd9auOQAAsPGsNjRf090vW9OWAADABrXaS879fVX9clUdVVVH7HisacsAAGCDWO1I83HTz2ctKOskt9q9zQEAgI1nVaG5u2+51g0BAICNalWhuaqeuFR5d//v3dscAADYeFY7PePuC57vn+QBSc5IIjQDALDHW+30jF9Z+HtV3SjJX69JiwAAYINZ7dUzFvtGktvszoYAAMBGtdo5zX+f2dUykmTvJLdP8qa1ahQAAGwkq53T/KIFz69J8rnuvnAN2gMAABvOqqZndPcHknwiySFJDk/yrbVsFAAAbCSrCs1V9dgkH0nyc0kem+S0qnrMWjYMAAA2itVOzzghyd27+9IkqarNSf4xyUlr1TAAANgoVnv1jL12BObJl3fitQAAcIO22pHmd1bVu5K8fvr955O8fW2aBAAAG8uKobmqbp3kpt39rKp6dJL7JqkkpyZ53a5WWlWHJXllkjtmdim7X+ruU3d1ewAAsJZGI80vTvJbSdLdb0nyliSpqq3Tsp/ZxXr/Z5J3dvdjqmrfJAfu4nYAAGDNjULzlu7+6OLC7t5WVVt2pcKqOjTJjyd50rStb8Ul7AAA2MBGJ/Ptv8KyA3axzlsl2Z7kr6rq36rqlVV10OKVqur4qtpWVdu2b9++i1UBAMD1NwrN/1pVT1lcWFVPTnL6Lta5Kcldk7ysu++S5OtJnr14pe4+sbu3dvfWzZs372JVAABw/Y2mZ/xakrdW1ePzvZC8Ncm+SR61i3VemOTC7j5t+v2kLBGaAQBgo1gxNHf3JUnuXVX3y+xKF0nyD9393l2tsLu/VFVfqKrbdfcnkzwgycd3dXsAALDWVnWd5u5+X5L37cZ6fyXJ66YrZ3wmyS/uxm0DAMButdqbm+xW3X1mZtM8AABgw3MrbAAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGJhbaK6qvavq36rqbfNqAwAArMY8R5p/Ncm5c6wfAABWZS6huaqOSfLTSV45j/oBAGBnzGuk+cVJfjPJvy+3QlUdX1Xbqmrb9u3b161hAACw2LqH5qp6eJJLu/v0ldbr7hO7e2t3b928efM6tQ4AAK5rHiPN90nyH6vqgiRvSHL/qnrtHNoBAACrsu6hubuf093HdPeWJI9L8t7ufsJ6twMAAFbLdZoBAGBg0zwr7+73J3n/PNsAAAAjRpoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBg3UNzVR1bVe+rqnOr6pyq+tX1bgMAAOyMTXOo85okz+juM6rqkCSnV9Up3f3xObQFAACG1n2kubsv7u4zpudXJTk3ydHr3Q4AAFituc5prqotSe6S5LR5tgMAAFYyt9BcVQcn+dskv9bdVy6x/Piq2lZV27Zv377+DUzyP0751FzqBQBgY5lLaK6qfTILzK/r7rcstU53n9jdW7t76+bNm9e3gQAAsMA8rp5RSf4yybnd/WfrXT8AAOyseYw03yfJLyS5f1WdOT0eNod2AADAqqz7Jee6+5+T1HrXCwAAu8odAQEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGNs27ARvVBz61PW/a9oWcdeEVOXT/fXLEQfvmTsfeKFtvcUSOOfyAVNW8mwgAwDoRmpexVyWb9qpc/vVv5YLLvp7tV12dV3/ogiTJzW60f376R47Ko+96TG5/1KHzbSgAAGtOaF7Gj91mcx5912Py6w+8bZLkO//e+eSXrsq2z12eD37qsvzVv1yQV/zTZ3OHow7N4+958zzqLkfnwH19nAAAeyIpb5X23qtyh5sdmjvc7NA88V5bcvnXv5WTz/xi3rTtwpzw1rPzgnd8Ij9/92PzxHttybFHHDjv5gIAsBsJzbvoiIP2zZPuc8scd+8t2fa5r+TVH7ogr/qXC/LKf/5sHvBDN8mT7n3L3OfWNzb3GQBgDyA0X09VlbtvOSJ333JELv7qN/O6D38+r//I5/OP556WW9/k4Bx3r1vk0Xc9Jgft56MGALihmssl56rqIVX1yar6dFU9ex5tWAtH3eiAPPPBt8u/PPv++dOfu1MO2GfvPPfvzsk9//A9+c2Tzsr7PnFprr7mO/NuJgAAO2ndhz+rau8kf5HkgUkuTPKvVXVyd398vduyVvbfZ+/87N2OyaPvenTO+PwVed2HP5d3fOxLedO2C3PIfptyzx+8ce6+5fDcfcsRuf1Rh2b/ffaed5MBAFjBPOYM3CPJp7v7M0lSVW9I8ogke0xo3qGqcrdbHJ673eLwXH3Nd/Kh87+cd5/zpZx6/pdzyscvSTK7tN3Njzgwt77JwTn2iANz00P3z00P3S+HHbBvDtx37xy476YcuN/es+f7bMp+++yVqqRS2auSvapmv5s7DQCwZuYRmo9O8oUFv1+Y5Efn0I51td+mvXO/290k97vdTZIkl171f3L6BV/JuV+6Kp++9Kp8+tKv5cOfuTxfu/qaXa5jcYjeawrX8jRwQ9U97xbMV+f7+wPQ/9+/jj38gLznGT8572ZcyzxC81IR7jr7RVUdn+T46devVdUn17RVSzvyN5LL5lAvKzsy+mUj0i8bl77ZmPTLxqRfNoDzktQzr1W0nv1yi6UK5xGaL0xy7ILfj0ly0eKVuvvEJCeuV6OWUlXbunvrPNvAdemXjUm/bFz6ZmPSLxuTftmYNkK/zOPqGf+a5DZVdcuq2jfJ45KcPId2AADAqqz7SHN3X1NVT0vyriR7J3lVd5+z3u0AAIDVmssdN7r77UnePo+6d9Jcp4ewLP2yMemXjUvfbEz6ZWPSLxvT3Pul+vv91FQAABiYyx0BAQDghkRoXsaeeqvvjaSqLqiqj1XVmVW1bSo7oqpOqarzpp+HL1j/OVN/fLKqHryg/G7Tdj5dVS+p6U4vVbVfVb1xKj+tqras+5u8AaiqV1XVpVV19oKydemHqjpuquO8qjpund7yDcYyffO8qvridNycWVUPW7BM36yxqjq2qt5XVedW1TlV9atTuWNmjlboF8fLHFXV/lX1kao6a+qX50/lN8zjpbs9Fj0yO0Hx/CS3SrJvkrOS3GHe7drTHkkuSHLkorIXJnn29PzZSV4wPb/D1A/7Jbnl1D97T8s+kuRemV0D/B1JHjqV/3KSl0/PH5fkjfN+zxvxkeTHk9w1ydnr2Q9Jjkjymenn4dPzw+f9eWykxzJ987wkz1xiXX2zPn1yVJK7Ts8PSfKp6bN3zGzMfnG8zLdfKsnB0/N9kpyW5J431OPFSPPSvnur7+7+VpIdt/pm7T0iyWum569J8sgF5W/o7qu7+7NJPp3kHlV1VJJDu/vUnh0l/3vRa3Zs66QkD9jxlynf090fTHL5ouL16IcHJzmluy/v7q8kOSXJQ3b3+7shW6ZvlqNv1kF3X9zdZ0zPr0pybmZ3unXMzNEK/bIc/bIOeuZr06/7TI/ODfR4EZqXttStvlc6+Ng1neTdVXV6ze4AmSQ37e6Lk9k/gkluMpUv1ydHT88Xl1/rNd19TZKvJrnxGryPPdF69IPjbNc9rao+WrPpGzu+1tQ362z6GvgumY2eOWY2iEX9kjhe5qqq9q6qM5NcmlmIvcEeL0Lz0lZ1q2+ut/t0912TPDTJf62qH19h3eX6ZKW+0o+73+7sB/2za16W5AeT3DnJxUn+dCrXN+uoqg5O8rdJfq27r1xp1SXK9MsaWaJfHC9z1t3f6e47Z3YH6HtU1R1XWH1D94vQvLRV3eqb66e7L5p+XprkrZlNi7lk+hom089Lp9WX65MLp+eLy6/1mqralORGWf1X3d/v1qMfHGe7oLsvmf4T+vckr8jsuEn0zbqpqn0yC2av6+63TMWOmTlbql8cLxtHd1+R5P2ZTZG4QR4vQvPS3Op7jVXVQVV1yI7nSR6U5OzMPucdZ7gel+TvpucnJ3ncdJbsLZPcJslHpq91rqqqe05zmJ646DU7tvWYJO+d5kIxth798K4kD6qqw6evTB80lbGCHf/RTB6V2XGT6Jt1MX2Gf5nk3O7+swWLHDNztFy/OF7mq6o2V9Vh0/MDkvxUkk/khnq8XJ+zCPfkR5KHZXb27flJTph3e/a0R2ZXJjlrepyz4zPObB7Se5KcN/08YsFrTpj645OZzpqdyrdm9g/h+Ulemu/dtGf/JG/O7ESCjyS51bzf90Z8JHl9Zl9bfjuzv8yfvF79kOSXpvJPJ/nFeX8WG+2xTN/8dZKPJfloZv9ZHKVv1rVP7pvZV7wfTXLm9HiYY2bD9ovjZb798iNJ/m36/M9O8jtT+Q3yeHFHQAAAGDA9AwAABoRmAAAYEJoBAGBAaAYAgAGhGQAABoRmgDmoqudV1TNXWP7IqrrDKrd1fFV9Ynp8pKruu2DZj1XVOVV1ZlXdvqq+OT0/q6o+VFW3m9bbWlUvWWb7d66qh6227QB7IqEZYGN6ZJJhaK6qhyf5f5Pct7t/KMlTk/xNVf3AtMrjk7yoZ7ex/WaS87v7zt19pySvSfJbSdLd27r76Utsf1NmtyB+2OJlAN9PXKcZYJ1U1QmZ3cnqC0m2Jzk9yVeTHJ9k38wuwP8LmYXUt03LvprkZ6dN/EWSzUm+keQp3f2JqvqnJL/b3e9dUM/vT08/l+SF0zY+lNlNA97W3Xec1ntWkqO7+9eq6ieTPLO7H15Vz0tysyRbklyW2Y0jDkjyxSR/lOT2SW6e2U2Kbp7kxd295Cg1wJ5i07wbAPD9oKruluRxSe6S2b+9Z2QWmt/S3a+Y1vmDJE/u7j+vqpMzC7gnTcvek+Sp3X1eVf1okv+V5P5JfnjazkLbkhzX3c+dpmq8rbtPqqotSX6wqs5MckiSA5P86DJNvltmo9ffrKonJdna3U+b2vK8JD+U5H7Tdj5ZVS/r7m9frw8JYAMTmgHWx48leWt3fyNJplCcJHecwvJhSQ5O8q7FL6yqg5PcO8mbq2pH8X4r1FWZ3VJ4KedPUzVSVT+f5MQkD1livZO7+5sr1PEP3X11kqur6tIkN83sVt8AeyShGWD9LBVkX53kkd191jSi+5NLrLNXkit2hN1FPp7ZqPB7F5TddSofOTnJXy2z7OuD11694Pl34v8TYA/nRECA9fHBJI+qqgOq6pAkPzOVH5Lk4qraJ7OT9na4alqW7r4yyWer6ueSpGbuNK33wiQvqKobT8vunORJmU3fGLlvkvNXsd532wLw/crIAMA66O4zquqNSc7M7AS9f5oWPTfJaVPZx/K9cPqGJK+oqqcneUxmgfplVfXbSfaZlp/V3SdX1dFJPlRVnVnAfUJ3X7xMU3bMaa4k30ryn1fR/Pclefb0uj9a9ZsG2IO4egYAAAyYngEAAANCMwAADAjNAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMDA/wXjfDOav5xsQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a list of the features.\n",
    "got_list_1 = ['dateOfBirth','age']\n",
    "# Creating a loop to print a histogram for every variable.\n",
    "for j in got_list_1:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# Using seaborn to create the plots. \n",
    "    sns.histplot(data = got,\n",
    "          x      = j,\n",
    "          kde    = True)\n",
    "\n",
    "# Title and axis labels.\n",
    "    plt.title(label   = (f\"\"\"Original Distribution of: {j}\"\"\"))\n",
    "    plt.xlabel(xlabel = j) # avoiding using dataset labels\n",
    "    plt.ylabel(ylabel = \"Count\")\n",
    "    plt.ylim([0, 13])\n",
    "\n",
    "# Displaying the histograms.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324684a",
   "metadata": {},
   "source": [
    "Now we can also observe something, most of the data is between a 'standard range', but there are some weird very big outliers. Nevertheless, they might be legit data, so to not get distorted by those extreme values, I will fill in the empty values with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6ccfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the median.\n",
    "birth_date_median = got['dateOfBirth'].median()\n",
    "# Substituting the median.\n",
    "got['dateOfBirth'] = got['dateOfBirth'].fillna(birth_date_median).round(4)\n",
    "# Finding the median.\n",
    "age_median = got['age'].median()\n",
    "# Substituting the median.\n",
    "got['age'] = got['age'].fillna(age_median).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df405a80",
   "metadata": {},
   "source": [
    "Now I am filling in the empty values of the isAlive... If they are missing values, I will substitute with a 0 assuming they are dead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b04d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling out empty values with 0.\n",
    "got['isAliveMother'] = got['isAliveMother'].fillna(0)\n",
    "got['isAliveFather'] = got['isAliveFather'].fillna(0)\n",
    "got['isAliveSpouse'] = got['isAliveSpouse'].fillna(0)\n",
    "got['isAliveHeir'] = got['isAliveHeir'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9be7fe",
   "metadata": {},
   "source": [
    "Now I will engineer new features to try to improve the model, first will be if they noble and popular at the same time. This is because I did some research and it pointed out the following:\n",
    "- Noble is more likely to be alive\n",
    "- Popular is more likely to be alive\n",
    "- If they are in book one most likely dead\n",
    "- If they are married and noble most likely alive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1379fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createing new feature.\n",
    "got['n_pop'] =0\n",
    "# Creating loop to run through the dataframe.\n",
    "for index, val in got.iterrows():\n",
    "    # Checking for popular.\n",
    "    if got.loc[ index , 'popularity'] >= 0.5:\n",
    "        got.loc[index, 'n_pop'] = 1\n",
    "    else:\n",
    "        got.loc[index, 'n_pop'] = 0\n",
    "        \n",
    "# Createing new feature.        \n",
    "got['n_pop_nob'] =0\n",
    "# Creating loop to run through the dataframe.\n",
    "for index, val in got.iterrows():\n",
    "    # Setting up condition.\n",
    "    if got.loc[ index , 'n_pop'] == got.loc[ index , 'isNoble']:\n",
    "        got.loc[index, 'n_pop_nob'] = 1\n",
    "    else:\n",
    "        got.loc[index, 'n_pop_nob'] = 0\n",
    "        \n",
    "# Createing new feature.\n",
    "got['n_b1_pop'] =0\n",
    "# Creating loop to run through the dataframe.\n",
    "for index, val in got.iterrows():\n",
    "    # Setting up condition.\n",
    "    if got.loc[ index , 'n_pop'] == got.loc[ index , 'book1_A_Game_Of_Thrones']:\n",
    "        got.loc[index, 'n_b1_pop'] = 0\n",
    "    else:\n",
    "        got.loc[index, 'n_b1_pop'] = 1\n",
    "\n",
    "# Createing new feature.\n",
    "got['n_married_popular'] =0\n",
    "# Creating loop to run through the dataframe.\n",
    "for index, val in got.iterrows():\n",
    "    # Setting up condition.\n",
    "    if got.loc[ index , 'n_pop'] == got.loc[ index , 'isMarried']:\n",
    "        got.loc[index, 'n_married_popular'] = 1\n",
    "    else:\n",
    "        got.loc[index, 'n_married_popular'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061ef03",
   "metadata": {},
   "source": [
    "Dropping categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2714e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping categorical features and S.No.\n",
    "got = got.drop(['S.No'],axis=1)\n",
    "got = got.drop(['name'],axis=1)\n",
    "got = got.drop(['house'],axis=1)\n",
    "got = got.drop(['title'],axis=1)\n",
    "got = got.drop(['culture'],axis=1)\n",
    "got = got.drop(['mother'],axis=1)\n",
    "got = got.drop(['father'],axis=1)\n",
    "got = got.drop(['heir'],axis=1)\n",
    "got = got.drop(['spouse'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "625ff47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isAlive                       1.00\n",
       "book4_A_Feast_For_Crows       0.27\n",
       "m_dateOfBirth                 0.15\n",
       "m_age                         0.15\n",
       "m_isAliveFather               0.14\n",
       "m_isAliveMother               0.14\n",
       "m_father                      0.14\n",
       "m_mother                      0.14\n",
       "m_isAliveHeir                 0.13\n",
       "m_heir                        0.13\n",
       "n_married_popular             0.09\n",
       "n_pop_nob                     0.06\n",
       "m_isAliveSpouse               0.05\n",
       "m_spouse                      0.05\n",
       "age                           0.05\n",
       "m_house                       0.04\n",
       "m_culture                     0.04\n",
       "m_title                       0.04\n",
       "book5_A_Dance_with_Dragons    0.03\n",
       "book3_A_Storm_Of_Swords       0.01\n",
       "isAliveSpouse                -0.01\n",
       "male                         -0.03\n",
       "isAliveFather                -0.04\n",
       "isNoble                      -0.04\n",
       "dateOfBirth                  -0.05\n",
       "isMarried                    -0.05\n",
       "book2_A_Clash_Of_Kings       -0.07\n",
       "isAliveHeir                  -0.08\n",
       "isAliveMother                -0.12\n",
       "n_pop                        -0.12\n",
       "book1_A_Game_Of_Thrones      -0.15\n",
       "popularity                   -0.18\n",
       "n_b1_pop                     -0.18\n",
       "numDeadRelations             -0.19\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for correlation.\n",
    "got_corr = got.corr(method = 'pearson').round(decimals = 2)\n",
    "got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa84a85",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f98c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring explanatory variables.\n",
    "got_data = got.drop('isAlive',axis = 1)\n",
    "# Declaring response variable.\n",
    "got_target = got.loc[ : ,'isAlive']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03d9c5a",
   "metadata": {},
   "source": [
    "Now the split will be made with the assignments criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed9e0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.75\n",
      "0    0.25\n",
      "Name: isAlive, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.74\n",
      "0    0.26\n",
      "Name: isAlive, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-test split with stratification.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "\n",
    "\n",
    "# Merging training data for statsmodels.\n",
    "got_train = pd.concat([x_train, y_train], axis = 1)\n",
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59ab49",
   "metadata": {},
   "source": [
    "Running logistic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827f780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435888\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.231</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1542.4811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 21:35</td>       <td>BIC:</td>         <td>1586.2247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-763.24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>6.3572e-95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-62.7595</td>  <td>8.1140</td>  <td>-7.7347</td> <td>0.0000</td> <td>-78.6627</td> <td>-46.8563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dateOfBirth</th>              <td>0.2168</td>   <td>0.0276</td>  <td>7.8705</td>  <td>0.0000</td>  <td>0.1628</td>   <td>0.2708</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th>  <td>-0.6013</td>  <td>0.1608</td>  <td>-3.7402</td> <td>0.0002</td>  <td>-0.9164</td>  <td>-0.2862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>   <td>-0.6211</td>  <td>0.1451</td>  <td>-4.2815</td> <td>0.0000</td>  <td>-0.9054</td>  <td>-0.3368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book3_A_Storm_Of_Swords</th>  <td>-0.4926</td>  <td>0.1509</td>  <td>-3.2644</td> <td>0.0011</td>  <td>-0.7884</td>  <td>-0.1969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th>  <td>1.3876</td>   <td>0.1497</td>  <td>9.2699</td>  <td>0.0000</td>  <td>1.0942</td>   <td>1.6809</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                      <td>0.2169</td>   <td>0.0276</td>  <td>7.8714</td>  <td>0.0000</td>  <td>0.1629</td>   <td>0.2709</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>               <td>-2.7485</td>  <td>0.3964</td>  <td>-6.9329</td> <td>0.0000</td>  <td>-3.5255</td>  <td>-1.9715</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                              Results: Logit\n",
       "==========================================================================\n",
       "Model:                 Logit               Pseudo R-squared:    0.231     \n",
       "Dependent Variable:    isAlive             AIC:                 1542.4811 \n",
       "Date:                  2021-12-05 21:35    BIC:                 1586.2247 \n",
       "No. Observations:      1751                Log-Likelihood:      -763.24   \n",
       "Df Model:              7                   LL-Null:             -992.53   \n",
       "Df Residuals:          1743                LLR p-value:         6.3572e-95\n",
       "Converged:             1.0000              Scale:               1.0000    \n",
       "No. Iterations:        10.0000                                            \n",
       "--------------------------------------------------------------------------\n",
       "                         Coef.   Std.Err.    z    P>|z|   [0.025   0.975] \n",
       "--------------------------------------------------------------------------\n",
       "Intercept               -62.7595   8.1140 -7.7347 0.0000 -78.6627 -46.8563\n",
       "dateOfBirth               0.2168   0.0276  7.8705 0.0000   0.1628   0.2708\n",
       "book1_A_Game_Of_Thrones  -0.6013   0.1608 -3.7402 0.0002  -0.9164  -0.2862\n",
       "book2_A_Clash_Of_Kings   -0.6211   0.1451 -4.2815 0.0000  -0.9054  -0.3368\n",
       "book3_A_Storm_Of_Swords  -0.4926   0.1509 -3.2644 0.0011  -0.7884  -0.1969\n",
       "book4_A_Feast_For_Crows   1.3876   0.1497  9.2699 0.0000   1.0942   1.6809\n",
       "age                       0.2169   0.0276  7.8714 0.0000   0.1629   0.2709\n",
       "popularity               -2.7485   0.3964 -6.9329 0.0000  -3.5255  -1.9715\n",
       "==========================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a logistic regression model object.\n",
    "logistic_small = smf.logit(formula = \"\"\"isAlive ~  dateOfBirth +\n",
    "                                                    book1_A_Game_Of_Thrones +\n",
    "                                                    book2_A_Clash_Of_Kings +\n",
    "                                                    book3_A_Storm_Of_Swords +\n",
    "                                                    book4_A_Feast_For_Crows +\n",
    "                                                    age +\n",
    "                                                    popularity\"\"\",\n",
    "                           data    = got_train)\n",
    "\n",
    "\n",
    "# Fitting the model object.\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# Checking the results summary.\n",
    "results_logistic.summary2() # Summary2() has AIC and BIC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4191bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.433400\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.235</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1545.7658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 21:35</td>       <td>BIC:</td>         <td>1622.3170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-758.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>13</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1737</td>         <td>LLR p-value:</td>    <td>1.2730e-91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th>  <th>[0.025</th>   <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>-64.1092</td>  <td>8.2581</td>  <td>-7.7632</td> <td>0.0000</td> <td>-80.2948</td> <td>-47.9237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dateOfBirth</th>                 <td>0.2209</td>   <td>0.0280</td>  <td>7.8853</td>  <td>0.0000</td>  <td>0.1660</td>   <td>0.2757</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th>     <td>-0.5520</td>  <td>0.1652</td>  <td>-3.3406</td> <td>0.0008</td>  <td>-0.8758</td>  <td>-0.2281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>      <td>-0.6228</td>  <td>0.1471</td>  <td>-4.2338</td> <td>0.0000</td>  <td>-0.9111</td>  <td>-0.3345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book3_A_Storm_Of_Swords</th>     <td>-0.4899</td>  <td>0.1536</td>  <td>-3.1887</td> <td>0.0014</td>  <td>-0.7910</td>  <td>-0.1888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th>     <td>1.4070</td>   <td>0.1616</td>  <td>8.7087</td>  <td>0.0000</td>  <td>1.0903</td>   <td>1.7236</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book5_A_Dance_with_Dragons</th>  <td>-0.0947</td>  <td>0.1554</td>  <td>-0.6093</td> <td>0.5424</td>  <td>-0.3993</td>  <td>0.2099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isMarried</th>                   <td>0.3102</td>   <td>0.2203</td>  <td>1.4082</td>  <td>0.1591</td>  <td>-0.1215</td>  <td>0.7420</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isNoble</th>                     <td>0.1355</td>   <td>0.1347</td>  <td>1.0060</td>  <td>0.3144</td>  <td>-0.1285</td>  <td>0.3994</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                         <td>0.2209</td>   <td>0.0280</td>  <td>7.8861</td>  <td>0.0000</td>  <td>0.1660</td>   <td>0.2758</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>            <td>-0.0875</td>  <td>0.0616</td>  <td>-1.4205</td> <td>0.1555</td>  <td>-0.2083</td>  <td>0.0332</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>                  <td>-2.4801</td>  <td>0.5368</td>  <td>-4.6205</td> <td>0.0000</td>  <td>-3.5321</td>  <td>-1.4281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_house</th>                     <td>0.3369</td>   <td>0.1654</td>  <td>2.0371</td>  <td>0.0416</td>  <td>0.0128</td>   <td>0.6611</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_culture</th>                   <td>0.0100</td>   <td>0.1407</td>  <td>0.0711</td>  <td>0.9434</td>  <td>-0.2658</td>  <td>0.2858</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                               Results: Logit\n",
       "=============================================================================\n",
       "Model:                  Logit                Pseudo R-squared:     0.235     \n",
       "Dependent Variable:     isAlive              AIC:                  1545.7658 \n",
       "Date:                   2021-12-05 21:35     BIC:                  1622.3170 \n",
       "No. Observations:       1751                 Log-Likelihood:       -758.88   \n",
       "Df Model:               13                   LL-Null:              -992.53   \n",
       "Df Residuals:           1737                 LLR p-value:          1.2730e-91\n",
       "Converged:              1.0000               Scale:                1.0000    \n",
       "No. Iterations:         10.0000                                              \n",
       "-----------------------------------------------------------------------------\n",
       "                            Coef.   Std.Err.    z    P>|z|   [0.025   0.975] \n",
       "-----------------------------------------------------------------------------\n",
       "Intercept                  -64.1092   8.2581 -7.7632 0.0000 -80.2948 -47.9237\n",
       "dateOfBirth                  0.2209   0.0280  7.8853 0.0000   0.1660   0.2757\n",
       "book1_A_Game_Of_Thrones     -0.5520   0.1652 -3.3406 0.0008  -0.8758  -0.2281\n",
       "book2_A_Clash_Of_Kings      -0.6228   0.1471 -4.2338 0.0000  -0.9111  -0.3345\n",
       "book3_A_Storm_Of_Swords     -0.4899   0.1536 -3.1887 0.0014  -0.7910  -0.1888\n",
       "book4_A_Feast_For_Crows      1.4070   0.1616  8.7087 0.0000   1.0903   1.7236\n",
       "book5_A_Dance_with_Dragons  -0.0947   0.1554 -0.6093 0.5424  -0.3993   0.2099\n",
       "isMarried                    0.3102   0.2203  1.4082 0.1591  -0.1215   0.7420\n",
       "isNoble                      0.1355   0.1347  1.0060 0.3144  -0.1285   0.3994\n",
       "age                          0.2209   0.0280  7.8861 0.0000   0.1660   0.2758\n",
       "numDeadRelations            -0.0875   0.0616 -1.4205 0.1555  -0.2083   0.0332\n",
       "popularity                  -2.4801   0.5368 -4.6205 0.0000  -3.5321  -1.4281\n",
       "m_house                      0.3369   0.1654  2.0371 0.0416   0.0128   0.6611\n",
       "m_culture                    0.0100   0.1407  0.0711 0.9434  -0.2658   0.2858\n",
       "=============================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a logistic regression model object.\n",
    "logistic_full = smf.logit(formula = \"\"\"  isAlive ~  dateOfBirth +\n",
    "                                                    book1_A_Game_Of_Thrones +\n",
    "                                                    book2_A_Clash_Of_Kings +\n",
    "                                                    book3_A_Storm_Of_Swords +\n",
    "                                                    book4_A_Feast_For_Crows +\n",
    "                                                    book5_A_Dance_with_Dragons +\n",
    "                                                    isMarried +\n",
    "                                                    isNoble +\n",
    "                                                    age +\n",
    "                                                    numDeadRelations +\n",
    "                                                    popularity +\n",
    "                                                    m_house+\n",
    "                                                    m_culture \"\"\",\n",
    "                                         data    = got_train)\n",
    "\n",
    "\n",
    "# Fitting the model object.\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# Checking the results summary.\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbea294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.432162\n",
      "         Iterations 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.238</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1551.4303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 21:35</td>       <td>BIC:</td>         <td>1655.3212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-756.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>18</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1732</td>         <td>LLR p-value:</td>    <td>9.4448e-89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>11.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                <th>Coef.</th>    <th>Std.Err.</th>      <th>z</th>     <th>P>|z|</th>     <th>[0.025</th>        <th>0.975]</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>-41.4174</td> <td>9267076.5572</td> <td>-0.0000</td> <td>1.0000</td> <td>-18163177.7114</td> <td>18163094.8766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dateOfBirth</th>                 <td>0.2093</td>     <td>0.0273</td>    <td>7.6802</td>  <td>0.0000</td>     <td>0.1559</td>        <td>0.2628</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th>     <td>-0.5959</td>    <td>0.1665</td>    <td>-3.5781</td> <td>0.0003</td>     <td>-0.9223</td>       <td>-0.2695</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>      <td>-0.6393</td>    <td>0.1476</td>    <td>-4.3318</td> <td>0.0000</td>     <td>-0.9285</td>       <td>-0.3500</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book3_A_Storm_Of_Swords</th>     <td>-0.5202</td>    <td>0.1551</td>    <td>-3.3538</td> <td>0.0008</td>     <td>-0.8242</td>       <td>-0.2162</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th>     <td>1.3997</td>     <td>0.1623</td>    <td>8.6240</td>  <td>0.0000</td>     <td>1.0816</td>        <td>1.7178</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book5_A_Dance_with_Dragons</th>  <td>-0.1186</td>    <td>0.1560</td>    <td>-0.7603</td> <td>0.4471</td>     <td>-0.4244</td>       <td>0.1872</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isMarried</th>                  <td>-20.5890</td> <td>9267076.5572</td> <td>-0.0000</td> <td>1.0000</td> <td>-18163156.8831</td> <td>18163115.7050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isNoble</th>                     <td>0.1114</td>     <td>0.4593</td>    <td>0.2426</td>  <td>0.8083</td>     <td>-0.7888</td>       <td>1.0116</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                         <td>0.2094</td>     <td>0.0273</td>    <td>7.6811</td>  <td>0.0000</td>     <td>0.1559</td>        <td>0.2628</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>            <td>-0.0630</td>    <td>0.0635</td>    <td>-0.9910</td> <td>0.3217</td>     <td>-0.1875</td>       <td>0.0616</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>                  <td>-2.0124</td>    <td>0.5901</td>    <td>-3.4101</td> <td>0.0006</td>     <td>-3.1690</td>       <td>-0.8558</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                        <td>-0.0427</td>    <td>0.2221</td>    <td>-0.1924</td> <td>0.8474</td>     <td>-0.4781</td>       <td>0.3926</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_title</th>                     <td>-0.0127</td>    <td>0.4929</td>    <td>-0.0257</td> <td>0.9795</td>     <td>-0.9788</td>       <td>0.9535</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_culture</th>                   <td>0.0533</td>     <td>0.1428</td>    <td>0.3736</td>  <td>0.7087</td>     <td>-0.2265</td>       <td>0.3332</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_mother</th>                    <td>1.0826</td>     <td>1.2273</td>    <td>0.8821</td>  <td>0.3777</td>     <td>-1.3228</td>       <td>3.4880</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_father</th>                    <td>0.1893</td>     <td>1.0492</td>    <td>0.1805</td>  <td>0.8568</td>     <td>-1.8670</td>       <td>2.2456</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_heir</th>                      <td>0.2816</td>     <td>0.9251</td>    <td>0.3044</td>  <td>0.7608</td>     <td>-1.5316</td>       <td>2.0948</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_house</th>                     <td>0.3974</td>     <td>0.1707</td>    <td>2.3279</td>  <td>0.0199</td>     <td>0.0628</td>        <td>0.7321</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_spouse</th>                   <td>-20.8282</td> <td>9267076.5572</td> <td>-0.0000</td> <td>1.0000</td> <td>-18163157.1223</td> <td>18163115.4658</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                                       Results: Logit\n",
       "============================================================================================\n",
       "Model:                       Logit                     Pseudo R-squared:          0.238     \n",
       "Dependent Variable:          isAlive                   AIC:                       1551.4303 \n",
       "Date:                        2021-12-05 21:35          BIC:                       1655.3212 \n",
       "No. Observations:            1751                      Log-Likelihood:            -756.72   \n",
       "Df Model:                    18                        LL-Null:                   -992.53   \n",
       "Df Residuals:                1732                      LLR p-value:               9.4448e-89\n",
       "Converged:                   1.0000                    Scale:                     1.0000    \n",
       "No. Iterations:              11.0000                                                        \n",
       "--------------------------------------------------------------------------------------------\n",
       "                            Coef.     Std.Err.      z    P>|z|      [0.025         0.975]   \n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  -41.4174 9267076.5572 -0.0000 1.0000 -18163177.7114 18163094.8766\n",
       "dateOfBirth                  0.2093       0.0273  7.6802 0.0000         0.1559        0.2628\n",
       "book1_A_Game_Of_Thrones     -0.5959       0.1665 -3.5781 0.0003        -0.9223       -0.2695\n",
       "book2_A_Clash_Of_Kings      -0.6393       0.1476 -4.3318 0.0000        -0.9285       -0.3500\n",
       "book3_A_Storm_Of_Swords     -0.5202       0.1551 -3.3538 0.0008        -0.8242       -0.2162\n",
       "book4_A_Feast_For_Crows      1.3997       0.1623  8.6240 0.0000         1.0816        1.7178\n",
       "book5_A_Dance_with_Dragons  -0.1186       0.1560 -0.7603 0.4471        -0.4244        0.1872\n",
       "isMarried                  -20.5890 9267076.5572 -0.0000 1.0000 -18163156.8831 18163115.7050\n",
       "isNoble                      0.1114       0.4593  0.2426 0.8083        -0.7888        1.0116\n",
       "age                          0.2094       0.0273  7.6811 0.0000         0.1559        0.2628\n",
       "numDeadRelations            -0.0630       0.0635 -0.9910 0.3217        -0.1875        0.0616\n",
       "popularity                  -2.0124       0.5901 -3.4101 0.0006        -3.1690       -0.8558\n",
       "male                        -0.0427       0.2221 -0.1924 0.8474        -0.4781        0.3926\n",
       "m_title                     -0.0127       0.4929 -0.0257 0.9795        -0.9788        0.9535\n",
       "m_culture                    0.0533       0.1428  0.3736 0.7087        -0.2265        0.3332\n",
       "m_mother                     1.0826       1.2273  0.8821 0.3777        -1.3228        3.4880\n",
       "m_father                     0.1893       1.0492  0.1805 0.8568        -1.8670        2.2456\n",
       "m_heir                       0.2816       0.9251  0.3044 0.7608        -1.5316        2.0948\n",
       "m_house                      0.3974       0.1707  2.3279 0.0199         0.0628        0.7321\n",
       "m_spouse                   -20.8282 9267076.5572 -0.0000 1.0000 -18163157.1223 18163115.4658\n",
       "============================================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a logistic regression model object.\n",
    "logistic_full = smf.logit(formula = \"\"\"  isAlive ~  dateOfBirth +\n",
    "                                                    book1_A_Game_Of_Thrones +\n",
    "                                                    book2_A_Clash_Of_Kings +\n",
    "                                                    book3_A_Storm_Of_Swords +\n",
    "                                                    book4_A_Feast_For_Crows +\n",
    "                                                    book5_A_Dance_with_Dragons +\n",
    "                                                    isMarried +\n",
    "                                                    isNoble +\n",
    "                                                    age +\n",
    "                                                    numDeadRelations +\n",
    "                                                    popularity +\n",
    "                                                    male +\n",
    "                                                    m_title +\n",
    "                                                    m_culture +\n",
    "                                                    m_mother+\n",
    "                                                    m_father+\n",
    "                                                    m_heir+\n",
    "                                                    m_house+\n",
    "                                                    m_spouse\"\"\",\n",
    "                                         data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object.\n",
    "results_full = logistic_full.fit()\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6179eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429348\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.243</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1547.5763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 21:35</td>       <td>BIC:</td>         <td>1667.8711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-751.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>21</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1729</td>         <td>LLR p-value:</td>    <td>1.0797e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>10.0000</td>             <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>-42.5737</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dateOfBirth</th>                 <td>0.2105</td>   <td>0.0277</td>  <td>7.5974</td>  <td>0.0000</td> <td>0.1562</td>  <td>0.2648</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th>     <td>-1.6094</td>  <td>0.8009</td>  <td>-2.0096</td> <td>0.0445</td> <td>-3.1791</td> <td>-0.0397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>      <td>-0.6239</td>  <td>0.1483</td>  <td>-4.2079</td> <td>0.0000</td> <td>-0.9144</td> <td>-0.3333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book3_A_Storm_Of_Swords</th>     <td>-0.4865</td>  <td>0.1564</td>  <td>-3.1112</td> <td>0.0019</td> <td>-0.7931</td> <td>-0.1800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th>     <td>1.4189</td>   <td>0.1634</td>  <td>8.6848</td>  <td>0.0000</td> <td>1.0987</td>  <td>1.7392</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book5_A_Dance_with_Dragons</th>  <td>-0.0994</td>  <td>0.1565</td>  <td>-0.6350</td> <td>0.5255</td> <td>-0.4061</td> <td>0.2074</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isMarried</th>                  <td>-21.1067</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isNoble</th>                     <td>0.8333</td>   <td>0.7614</td>  <td>1.0943</td>  <td>0.2738</td> <td>-0.6591</td> <td>2.3257</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                         <td>0.2105</td>   <td>0.0277</td>  <td>7.5982</td>  <td>0.0000</td> <td>0.1562</td>  <td>0.2648</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>            <td>-0.1135</td>  <td>0.0681</td>  <td>-1.6660</td> <td>0.0957</td> <td>-0.2470</td> <td>0.0200</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>                  <td>-3.8217</td>  <td>0.9039</td>  <td>-4.2280</td> <td>0.0000</td> <td>-5.5933</td> <td>-2.0501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                        <td>-0.0436</td>  <td>0.2244</td>  <td>-0.1942</td> <td>0.8461</td> <td>-0.4833</td> <td>0.3962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_title</th>                     <td>-0.0865</td>  <td>0.5023</td>  <td>-0.1722</td> <td>0.8633</td> <td>-1.0710</td> <td>0.8980</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_culture</th>                   <td>0.0444</td>   <td>0.1433</td>  <td>0.3098</td>  <td>0.7567</td> <td>-0.2365</td> <td>0.3253</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_house</th>                     <td>0.3753</td>   <td>0.1712</td>  <td>2.1923</td>  <td>0.0284</td> <td>0.0398</td>  <td>0.7107</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_spouse</th>                   <td>-21.4687</td>    <td>nan</td>     <td>nan</td>     <td>nan</td>    <td>nan</td>     <td>nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_mother</th>                    <td>1.6063</td>   <td>1.3268</td>  <td>1.2106</td>  <td>0.2260</td> <td>-0.9943</td> <td>4.2069</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_father</th>                    <td>0.1753</td>   <td>1.0187</td>  <td>0.1720</td>  <td>0.8634</td> <td>-1.8214</td> <td>2.1719</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_heir</th>                      <td>0.5648</td>   <td>0.9470</td>  <td>0.5963</td>  <td>0.5509</td> <td>-1.2914</td> <td>2.4209</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_pop</th>                       <td>2.2235</td>   <td>0.8318</td>  <td>2.6730</td>  <td>0.0075</td> <td>0.5931</td>  <td>3.8539</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_pop_nob</th>                   <td>0.7764</td>   <td>0.6462</td>  <td>1.2015</td>  <td>0.2296</td> <td>-0.4901</td> <td>2.0429</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_b1_pop</th>                    <td>1.0769</td>   <td>0.7945</td>  <td>1.3554</td>  <td>0.1753</td> <td>-0.4803</td> <td>2.6341</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                              Results: Logit\n",
       "===========================================================================\n",
       "Model:                  Logit               Pseudo R-squared:    0.243     \n",
       "Dependent Variable:     isAlive             AIC:                 1547.5763 \n",
       "Date:                   2021-12-05 21:35    BIC:                 1667.8711 \n",
       "No. Observations:       1751                Log-Likelihood:      -751.79   \n",
       "Df Model:               21                  LL-Null:             -992.53   \n",
       "Df Residuals:           1729                LLR p-value:         1.0797e-88\n",
       "Converged:              1.0000              Scale:               1.0000    \n",
       "No. Iterations:         10.0000                                            \n",
       "---------------------------------------------------------------------------\n",
       "                            Coef.   Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "---------------------------------------------------------------------------\n",
       "Intercept                  -42.5737      nan     nan    nan     nan     nan\n",
       "dateOfBirth                  0.2105   0.0277  7.5974 0.0000  0.1562  0.2648\n",
       "book1_A_Game_Of_Thrones     -1.6094   0.8009 -2.0096 0.0445 -3.1791 -0.0397\n",
       "book2_A_Clash_Of_Kings      -0.6239   0.1483 -4.2079 0.0000 -0.9144 -0.3333\n",
       "book3_A_Storm_Of_Swords     -0.4865   0.1564 -3.1112 0.0019 -0.7931 -0.1800\n",
       "book4_A_Feast_For_Crows      1.4189   0.1634  8.6848 0.0000  1.0987  1.7392\n",
       "book5_A_Dance_with_Dragons  -0.0994   0.1565 -0.6350 0.5255 -0.4061  0.2074\n",
       "isMarried                  -21.1067      nan     nan    nan     nan     nan\n",
       "isNoble                      0.8333   0.7614  1.0943 0.2738 -0.6591  2.3257\n",
       "age                          0.2105   0.0277  7.5982 0.0000  0.1562  0.2648\n",
       "numDeadRelations            -0.1135   0.0681 -1.6660 0.0957 -0.2470  0.0200\n",
       "popularity                  -3.8217   0.9039 -4.2280 0.0000 -5.5933 -2.0501\n",
       "male                        -0.0436   0.2244 -0.1942 0.8461 -0.4833  0.3962\n",
       "m_title                     -0.0865   0.5023 -0.1722 0.8633 -1.0710  0.8980\n",
       "m_culture                    0.0444   0.1433  0.3098 0.7567 -0.2365  0.3253\n",
       "m_house                      0.3753   0.1712  2.1923 0.0284  0.0398  0.7107\n",
       "m_spouse                   -21.4687      nan     nan    nan     nan     nan\n",
       "m_mother                     1.6063   1.3268  1.2106 0.2260 -0.9943  4.2069\n",
       "m_father                     0.1753   1.0187  0.1720 0.8634 -1.8214  2.1719\n",
       "m_heir                       0.5648   0.9470  0.5963 0.5509 -1.2914  2.4209\n",
       "n_pop                        2.2235   0.8318  2.6730 0.0075  0.5931  3.8539\n",
       "n_pop_nob                    0.7764   0.6462  1.2015 0.2296 -0.4901  2.0429\n",
       "n_b1_pop                     1.0769   0.7945  1.3554 0.1753 -0.4803  2.6341\n",
       "===========================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a logistic regression model object.\n",
    "logistic_full = smf.logit(formula = \"\"\"  isAlive ~  dateOfBirth +\n",
    "                                                    book1_A_Game_Of_Thrones +\n",
    "                                                    book2_A_Clash_Of_Kings +\n",
    "                                                    book3_A_Storm_Of_Swords +\n",
    "                                                    book4_A_Feast_For_Crows +\n",
    "                                                    book5_A_Dance_with_Dragons +\n",
    "                                                    isMarried +\n",
    "                                                    isNoble +\n",
    "                                                    age +\n",
    "                                                    numDeadRelations +\n",
    "                                                    popularity +\n",
    "                                                    male +\n",
    "                                                    m_title +\n",
    "                                                    m_culture +\n",
    "                                                    m_house +\n",
    "                                                    m_spouse +\n",
    "                                                    m_mother +\n",
    "                                                    m_father +\n",
    "                                                    m_heir +\n",
    "                                                    n_pop +\n",
    "                                                    n_pop_nob +\n",
    "                                                    n_b1_pop \n",
    "                                    \n",
    "                                                    \"\"\",\n",
    "                                         data    = got_train)\n",
    "\n",
    "\n",
    "# Fitting the model object.\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results summary.\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cd84827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7827\n",
      "LogReg Testing  ACCURACY: 0.8131\n",
      "LogReg Train-Test Gap   : 0.0304\n",
      "AUC Score        : 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanballester/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Creating a list with all the variables I will use in the models.\n",
    "candidate_dict = {\n",
    "\n",
    " # Model.\n",
    " 'logit_full'   : ['dateOfBirth','book1_A_Game_Of_Thrones',\n",
    "                   'book2_A_Clash_Of_Kings','book3_A_Storm_Of_Swords',\n",
    "                   'book4_A_Feast_For_Crows','book5_A_Dance_with_Dragons',\n",
    "                   'isMarried','isNoble','age','numDeadRelations',\n",
    "                   'popularity','m_house','n_b1_pop','n_pop_nob',\n",
    "                   'n_pop','m_age','n_married_popular']\n",
    "\n",
    "}\n",
    "\n",
    "# Train/test split with the model.\n",
    "got_data   =  got.loc[ : , candidate_dict['logit_full']]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# Same as before.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# Instantiating a logistic regression model.\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# Fitting the training data.\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting based on the testing set.\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# Scoring the results.\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# Saving scoring data for future use.\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# Displaying and saving the gap between training and testing.\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scoring with AUC.\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))\n",
    "\n",
    "\n",
    "# Saving AUC score.\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "343fa690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7827\n",
      "LogReg Testing  ACCURACY: 0.8131\n",
      "LogReg Train-Test Gap   : 0.0304\n",
      "AUC Score        : 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanballester/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Variables for the model.\n",
    "candidate_dict = {\n",
    "\n",
    " # Model.\n",
    " 'logit_full'   : ['dateOfBirth','book1_A_Game_Of_Thrones',\n",
    "                   'book2_A_Clash_Of_Kings','book3_A_Storm_Of_Swords',\n",
    "                   'book4_A_Feast_For_Crows','book5_A_Dance_with_Dragons',\n",
    "                   'isMarried','isNoble','age','numDeadRelations',\n",
    "                   'popularity','m_house','n_b1_pop','n_pop_nob',\n",
    "                   'n_pop','m_age','n_married_popular']\n",
    "\n",
    "}\n",
    "\n",
    "# Train/test split with the full model.\n",
    "got_data   =  got.loc[ : , candidate_dict['logit_full']]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model.\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data.\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set.\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results.\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# Saving scoring data for future use.\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# Displaying and saving the gap between training and testing.\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SCORING with AUC.\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))\n",
    "\n",
    "\n",
    "# Saving AUC score.\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f4e4c",
   "metadata": {},
   "source": [
    "Now I will do a full tree, pruned tree and a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f6bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using professors function for CART models.\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fee23c",
   "metadata": {},
   "source": [
    "Running a full tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6c3cba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.9568\n",
      "Full Tree Testing ACCURACY : 0.809\n",
      "Full Tree AUC Score: 0.7684\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object.\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data.\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data.\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model.\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# Saving scoring data for future use.\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC.\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba47034",
   "metadata": {},
   "source": [
    "Now a pruned tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c53e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8211\n",
      "Testing  ACCURACY: 0.8398\n",
      "AUC Score        : 0.7545\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object.\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 8,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data.\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data.\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model.\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# Saving scoring data for future use.\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# Saving auc score.\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df610212",
   "metadata": {},
   "source": [
    "Last a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9558c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  ACCURACY: 0.8348\n",
      "Testing  ACCURACY: 0.8439\n",
      "AUC Score        : 0.7174\n"
     ]
    }
   ],
   "source": [
    "RF_gini = RandomForestClassifier(n_estimators = 1000,\n",
    "                                     criterion = 'gini',\n",
    "                                     max_depth = 8,\n",
    "                                     min_samples_leaf = 4,\n",
    "                                     bootstrap = True,\n",
    "                                     warm_start = False,\n",
    "                                     random_state = 219)\n",
    "\n",
    "# Fitting model.\n",
    "RF_fit = RF_gini.fit(x_train, y_train)\n",
    "# Predicting.\n",
    "RF_pred = RF_gini.predict(x_test)\n",
    "# Saving scores.\n",
    "RF_aug = roc_auc_score(y_true  = y_test,y_score = RF_pred).round(4)\n",
    "RF_train_score = RF_fit.score(x_train, y_train).round(4)\n",
    "RF_test_score = RF_fit.score(x_test, y_test).round(4)\n",
    "# Displaying scores.\n",
    "print('Training  ACCURACY:', RF_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', RF_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = RF_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c44d25",
   "metadata": {},
   "source": [
    "Now I will create all the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5bb605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Tree True Negatives : 43\n",
      "Pruned Tree False Positives: 81\n",
      "Pruned Tree False Negatives: 10\n",
      "Pruned Tree True Positives : 353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the confusion matrix for logistic regression.\n",
    "logreg_tree_tn, \\\n",
    "logreg_tree_fp, \\\n",
    "logreg_tree_fn, \\\n",
    "logreg_tree_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# Printing each result one-by-one.\n",
    "print(f\"\"\"\n",
    "Pruned Tree True Negatives : {logreg_tree_tn}\n",
    "Pruned Tree False Positives: {logreg_tree_fp}\n",
    "Pruned Tree False Negatives: {logreg_tree_fn}\n",
    "Pruned Tree True Positives : {logreg_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca8d8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Tree True Negatives : 85\n",
      "Pruned Tree False Positives: 39\n",
      "Pruned Tree False Negatives: 54\n",
      "Pruned Tree True Positives : 309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the confusion matrix for full tree.\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# Printing each result one-by-one.\n",
    "print(f\"\"\"\n",
    "Pruned Tree True Negatives : {full_tree_tn}\n",
    "Pruned Tree False Positives: {full_tree_fp}\n",
    "Pruned Tree False Negatives: {full_tree_fn}\n",
    "Pruned Tree True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f753c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Tree True Negatives : 72\n",
      "Pruned Tree False Positives: 52\n",
      "Pruned Tree False Negatives: 26\n",
      "Pruned Tree True Positives : 337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the confusion matrix for pruned tree.\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# Printing each result one-by-one.\n",
    "print(f\"\"\"\n",
    "Pruned Tree True Negatives : {pruned_tree_tn}\n",
    "Pruned Tree False Positives: {pruned_tree_fp}\n",
    "Pruned Tree False Negatives: {pruned_tree_fn}\n",
    "Pruned Tree True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8cd385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned Tree True Negatives : 57\n",
      "Pruned Tree False Positives: 67\n",
      "Pruned Tree False Negatives: 9\n",
      "Pruned Tree True Positives : 354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the confusion matrix for random forest.\n",
    "RF_tn, \\\n",
    "RF_fp, \\\n",
    "RF_fn, \\\n",
    "RF_tp = confusion_matrix(y_true = y_test, y_pred = RF_pred).ravel()\n",
    "\n",
    "\n",
    "# Printing each result one-by-one.\n",
    "print(f\"\"\"\n",
    "Pruned Tree True Negatives : {RF_tn}\n",
    "Pruned Tree False Positives: {RF_fp}\n",
    "Pruned Tree False Negatives: {RF_fn}\n",
    "Pruned Tree True Positives : {RF_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72d6d7",
   "metadata": {},
   "source": [
    "Now creating a display table to display model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf9e9412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      Train score     Test score       Confusion Matrix (TN,FP,FN,TP)\n",
      "-----         ---------      --------------  --------------   ------------------------------\n",
      "Logistic       0.6596         0.7827          0.8131             (43, 81, 10, 353) \n",
      "Full Tree      0.7684          0.9568          0.809             (85, 39, 54, 309) \n",
      "Pruned Tree*   0.7545         0.8211          0.8398             (72, 52, 26, 337)        \n",
      "Random Forest  0.7174         0.8348          0.8439             (57, 67, 9, 354)\n",
      "\n",
      "* meaning that is my final model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>(43, 81, 10, 353)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>(85, 39, 54, 309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prunned Tree</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>(72, 52, 26, 337)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>(57, 67, 9, 354)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name  AUC Score  Training Accuracy  Testing Accuracy  \\\n",
       "0       Logistic     0.6596             0.7827            0.8131   \n",
       "1      Full Tree     0.7684             0.9568            0.8090   \n",
       "2   Prunned Tree     0.7545             0.8211            0.8398   \n",
       "3  Random Forest     0.7174             0.8348            0.8439   \n",
       "\n",
       "    Confusion Matrix  \n",
       "0  (43, 81, 10, 353)  \n",
       "1  (85, 39, 54, 309)  \n",
       "2  (72, 52, 26, 337)  \n",
       "3   (57, 67, 9, 354)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      Train score     Test score       Confusion Matrix (TN,FP,FN,TP)\n",
    "-----         ---------      --------------  --------------   ------------------------------\n",
    "Logistic       {logreg_auc_score}         {logreg_train_score}          {logreg_test_score}             {(logreg_tree_tn,logreg_tree_fp, logreg_tree_fn, logreg_tree_tp)} \n",
    "Full Tree      {full_tree_auc_score}          {full_tree_train_score}          {full_tree_test_score}             {(full_tree_tn,full_tree_fp, full_tree_fn, full_tree_tp)} \n",
    "Pruned Tree*   {pruned_tree_auc_score}         {pruned_tree_train_score}          {pruned_tree_test_score}             {(pruned_tree_tn,pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)}        \n",
    "Random Forest  {RF_aug}         {RF_train_score}          {RF_test_score}             {(RF_tn,RF_fp, RF_fn, RF_tp)}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print('* meaning that is my final model')\n",
    "# Creating a dictionary for model results for a dataframe.\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree','Prunned Tree', 'Random Forest'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, \n",
    "                   pruned_tree_auc_score, RF_aug],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score, RF_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score,full_tree_test_score,\n",
    "                           pruned_tree_test_score, RF_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tree_tn, logreg_tree_fp, logreg_tree_fn, logreg_tree_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                           (RF_tn, RF_fp, RF_fn, RF_tp)]}\n",
    "# Creating dataframe.\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "# Showing dataframe.\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b334624",
   "metadata": {},
   "source": [
    "The reason why I chose as my model Pruned Tree instead of Full Tree even if it had a slightly better AUC score was because the gap between train and test was too big for the Full Tree and the gap for Pruned was really small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
